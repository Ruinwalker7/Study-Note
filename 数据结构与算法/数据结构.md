# 数据结构与算法

## 绪论

### 基本概念

**数据元素：**组成数据的，有一点意义的基本单位

**数据项：**一个元素可以由若干数据项组成，是不可分割的最小单位

**数据对象：** **性质相同**的数据元素的组合，是数据的子集

**数据结构：**不同元素不是独立存在的，而是存在特定的关系，我们将这些关系成为结构

数据结构关注的是**数据元素之间的关系**和操作，不关心数据的具体内容

### 逻辑结构与物理结构

逻辑结构：数据对象中数据元素之间的关系，分为以下四种

**1. 集合结构：** 数据元素除了同属于一个集合外，它们之间没有任何其他关系

**2. 线性结构：** 一对一关系

**3. 树状结构：** 数据元素之间存在一对多的层次关系

**4. 图形结构：** 多对多的关系



物理结构（存储结构）：数据的逻辑结构再计算机中的存储形式

**顺序存储，链式存储，索引存储，散列存储**



## 算法

算法：解决特定问题求解步骤的一种描述

1. 有穷性：在执行有穷部后结束，且每一步都可以在有穷时间完成
2. 确定性：相同输入能得到相同输出
3. 可行性：有零个或多个输入，有一个或多个输出

### 算法效率的度量问题

#### 事后统计法

利用计算器对不同算法编制的程序运行时间进行比较，缺陷在于计算机硬件不同，没法比较，缺陷较大；有些算法不能事后统计，比如导弹发射。

#### 事前分析估计法

利用问题规模n来度量，考虑最高次项即可



### 算法时间复杂度

#### 算法时间复杂度的定义

$T(n)$ 是关于问题规模 $n$ 的函数，$T(n)=O(f(n))$。它表示随着问题规模n的增大，算法执行时间的增长率和$f(n)$的增长率相同，成为算法的渐进时间复杂度



用大写$O()$来体现算法时间复杂度的方法，我们称为**大O记法**

随着n的增大，$T(n)$增长最慢的称为最优算法

---

推导大O：

1. 用1代替所有加法常数
2. 只保留最高次项
3. 把最高次项系数变成1
3. 相乘的时候都保留



$O(1)<O(\log_2 n)<O( n \log_2 n)<O(n^2)<O(n^3$$)<O(2^n)<O(n!)<O(n^n)$

常对幂指接

如何从代码中推导时间复杂度：

1. 顺序执行的代码只影响常数项，不用考虑
2. 只用挑循环中的一个基本操作去分析他的执行次数与n的关系
3. 如果有多层嵌套循环，只需要关注最深层循环嵌套了几次

#### 三种时间复杂度

最坏、最好、平均：关注最坏和平均就行

#### 求时间复杂度的方法

时间复杂度是算法效率的度量，算法的时间复杂度与问题的输入规模有关

##### 递归树

<img src="assets/image-20230611083445191-16864436874611.png" alt="image-20230611083445191" style="zoom: 80%;" />

##### 主定理

在计算时间复杂度时，主定理（Master Theorem）是一种常用的方法，尤其适用于分治算法的递归时间复杂度的求解。主定理提供了一种直接分析递归关系的方法，以确定算法的渐近时间复杂度。主定理主要适用于以下形式的递归关系：

$$
T(n) = aT\left(\frac{n}{b}\right) + f(n)
$$
其中：
- $ a $ 是每次递归调用的分支数；
- $ \frac{n}{b} $ 是每个子问题的规模；
- $ f(n) $ 是在分解和合并阶段花费的时间。

主定理有三种情况，根据 $ f(n) $ 的增长速度与 $ n^{\log_b{a}} $ 的关系来判断时间复杂度。

1. 如果 $ f(n) = O(n^c) $ 且 $ c < \log_b{a} $，则
   $$ T(n) = \Theta(n^{\log_b{a}}) $$
   
2. 如果 $ f(n) = \Theta(n^{\log_b{a}}) $，则
   $$ T(n) = \Theta(n^{\log_b{a}} \log n) $$
   
3. 如果 $ f(n) = \Omega(n^c) $ 且 $ c > \log_b{a} $，并且 $ af\left(\frac{n}{b}\right) \leq kf(n) $ 对于某个常数 $ k < 1 $ 和足够大的 $ n $，则
   $$ T(n) = \Theta(f(n)) $$



假设有一个递归关系：$$ T(n) = 2T\left(\frac{n}{2}\right) + n $$

1. 首先，确定主定理中的参数：
   - $ a = 2 $
   - $ b = 2 $
   - $ f(n) = n $

2. 计算 $ n^{\log_b{a}} $：
   - $ \log_b{a} = \log_2{2} = 1 $
   - 因此， $ n^{\log_b{a}} = n^1 = n $

3. 比较 $ f(n) $ 与 $ n^{\log_b{a}} $：
   - 这里， $ f(n) = n $ 和 $ n^{\log_b{a}} = n $
   - 所以 $ f(n) = \Theta(n^{\log_b{a}}) $

根据主定理的情况2，我们可以得出：
$$
T(n) = \Theta(n \log n)
$$


### 算法空间复杂度

是指执行当前算法需要占用多少内存空间，我们通常用「空间复杂度」来描述。



## 线性表

### 线性表的定义和基本操作

零个或多个**相同类型**的数据元素的**有限序列**，一对一，有前有后

在负载的线性表中，一个数据元素可以由若干数据项组成

读取的时候时间复杂度都是 $O(1)$，插入或删除时，时间复杂度都是$O(n)$

数据元素的位数是从1开始的

优点：

1. 无需为表中元素之间的逻辑关系而增加额外的储存空间
2. 可以快速地存取表中任一位置的元素

缺点：

1. 插入和删除操作需要移动大量元素
2. 当线性表长度变化较大，难以确定存储空间容量

#### 基本操作

初始化表，销毁操作，插入操作，删除操作，按值查找，按位查找

### 线性表的顺序存储结构

逻辑上相邻的数据元素物理上也相邻

### 线性表的链式存储结构（链表）

链式结构中，除了要存储数据元素信息外，还要存储它的后继元素的存储地址

数据域：存储数据元素信息的域

指针域：存储直接后继位置的域

n个结点链成一个链表，即为线性表的链式存储结构

链表中的第一个节点的存储位置叫头指针

最后一个节点指针为“空”，通常用NULL表示

### 静态链表

用结构体数组实现，数组中包含数据元素和cur元素

### 循环链表

让最后一个指针指向头指针

### 双向链表

结构体中有两个指针，一个指前面一个指后面



## 栈与队列

#### 栈

##### 栈的定义

栈(stack)是限定仅在表尾进行插入和删除操作的线性表

栈顶：允许插入和删除的一端称为栈顶

栈底：另一端



##### 栈的抽象数据类型

理论上线性表的操作特性它都有，可是由于它的特殊性，插入和删除操作改名为push和pop



##### 两栈共享空间

为了节约内存空间，可以用一个数组来存放两个栈，这样需要一些技巧，比如建立以下数组

```c++
typedef struct
{
	int date[MAXSIZE];
	int top1;
	int top2;
}
```

当`top1+1=top2`时栈满



##### 中缀表达式转后缀表达式

两个栈实现，数字栈和符号栈



#### 队列

先进后出，一段进行插入（队尾），另一段只允许删除（队头）

##### 顺序储存不足

如果保证队头下标为0，则删除的时间复杂度为*O(n)*，插入为*O(1)*

如果不保证对头下标为0，则插入删除都为*O(1)*，但容易产生假溢出情况



## 串

0个或多个字符串组成的有序序列，又叫字符串



### KMP算法

题目：http://acm.hdu.edu.cn/showproblem.php?pid=1711

先对模式串建立next数组

```c++
#include <vector>
#include <iostream>
#include <string>

// 构建next数组
void buildNext(const std::string& pattern, std::vector<int>& next) {
    int m = pattern.length(), j = 0;
    next[0] = -1; // next数组初始化
    int t = -1;
    while (j < m - 1) {
        if (t < 0 || pattern[j] == pattern[t]) {
            ++j;
            ++t;
            if (pattern[j] != pattern[t]) {
                next[j] = t;
            } else {
                next[j] = next[t];
            }
        } else {
            t = next[t];
        }
    }
}

// KMP搜索算法
int KMP(const std::string& text, const std::string& pattern) {
    int n = text.length();
    int m = pattern.length();
    std::vector<int> next(m);
    buildNext(pattern, next); // 构建next数组
    int i = 0, j = 0;
    while (i < n) {
        if (j < 0 || text[i] == pattern[j]) { // 匹配成功或j为-1
            i++;
            j++;
        } else {
            j = next[j]; // 根据next数组跳转j
        }
        if (j == m) { // 完整匹配
            return i - m; // 返回匹配起始索引
        }
    }
    return -1; // 未找到匹配
}

int main() {
    std::string text = "ABABDABACDABABCABAB";
    std::string pattern = "ABABCABAB";
    int matchIndex = KMP(text, pattern);
    if (matchIndex != -1) {
        std::cout << "Pattern found at index " << matchIndex << std::endl;
    } else {
        std::cout << "Pattern not found" << std::endl;
    }
    return 0;
}
```



## 树

### 二叉树

左右区分 只有两个子树

特殊：

斜树：单偏

满二叉树：所以分支都有子树

完全二叉树：按顺序编号，同一层一定从左往右满的



### 遍历二叉树

前序，中序，后序，其实就是转换print的位置



### 哈夫曼树：

带权路径长度WPL最小的二叉树称为哈夫曼树

如何构造：在集合中选择权值最小的两个数，较小放左边，两数权重之和N1加入集合之中，重复网上种树

### 平衡二叉查找树（AVL）

AVL树中，任一节点对应的两棵子树的最大高度差为1，因此它也被称为**高度平衡树**。查找、插入和删除在平均和最坏情况下的时间复杂度都是$\displaystyle O(\log {n})$

**左右子树的高度相差不超过 1 的树为平衡二叉树。**

#### 定义

**平衡二叉查找树**（平衡二叉树）。它具有如下几个性质：

1. 可以是空树。
2. 假如不是空树，任何一个结点的左子树与右子树都是平衡二叉树，并且高度之差的绝对值不超过 1。

#### 节点结构

```c++
typedef struct AVLNode *Tree;

typedef int ElementType;

struct AVLNode{

    int depth; //深度，这里计算每个结点的深度，通过深度的比较可得出是否平衡

    Tree parent; //该结点的父节点

    ElementType val; //结点值

    Tree lchild;

    Tree rchild;

    AVLNode(int val=0) {
        parent = NULL;
        depth = 0;
        lchild = rchild = NULL;
        this->val=val;
    }
};
```

#### 平衡因子

**定义：**某节点的左子树与右子树的高度差即为该节点的平衡因子（BF,Balance Factor），在一棵平衡二叉树中，节点的平衡因子只能取 0 、1 或者 -1，分别对应着左右子树等高，左子树比较高，右子树比较高。

#### AVL树插入时的失衡与调整

插入一个节点后，可能会导致树不平衡，这时候就要从在新插入的结点向上查找，以第一个平衡因子的**绝对值**超过 1 的结点为根的子树称为最小不平衡子树。

可能会有很多子树失衡，但我们只需要调整最小不平衡子树

#### AVL树的四种插入方式

1. 左孩子的左子树插入节点

   一次右旋

2. 右孩子的右子树插入节点

   一次左旋

3. 左孩子的右子树插入节点

   先对左孩子进行左旋，再对当前节点右旋

4. 右孩子的左子树插入节点

   先对右孩子进行右旋，再对当前节点左旋

#### 代码实现

AVL树是一种自平衡二叉搜索树，它的每一个节点存储了一个平衡因子，这个平衡因子是左子树的高度和右子树的高度的差。对于任何一个节点，这个平衡因子的绝对值不能超过1。如果在插入或删除操作之后平衡因子超过了1，就需要通过旋转操作来恢复平衡。

以下是AVL树实现的核心部分，包括节点定义、插入、删除、以及旋转操作。

##### AVL树节点的定义

首先，我们定义AVL树的节点，每个节点包含数据、左右子节点的指针，以及一个表示节点高度的变量。

```cpp
struct AVLNode {
    int key;
    AVLNode *left;
    AVLNode *right;
    int height;

    AVLNode(int k) : key(k), left(nullptr), right(nullptr), height(1) {}
};
```

##### 计算节点高度

我们需要一个辅助函数来计算节点的高度，因为在进行旋转操作时需要知道子树的高度。

```cpp
int getHeight(AVLNode *N) {
    if (N == nullptr)
        return 0;
    return N->height;
}
```

##### 更新节点高度

在每次插入或删除操作之后，我们需要更新经过的节点的高度。

```cpp
void updateHeight(AVLNode *N) {
    N->height = 1 + max(getHeight(N->left), getHeight(N->right));
}
```

##### 平衡因子

计算节点的平衡因子，它是左子树高度减去右子树高度。

```cpp
int getBalance(AVLNode *N) {
    if (N == nullptr)
        return 0;
    return getHeight(N->left) - getHeight(N->right);
}
```

##### 旋转操作

为了保持树的平衡，我们需要实现四种旋转操作：左旋、右旋、左右旋和右左旋。

- **右旋**:

```cpp
AVLNode *rightRotate(AVLNode *y) {
    AVLNode *x = y->left;
    AVLNode *T2 = x->right;

    // Perform rotation
    x->right = y;
    y->left = T2;

    // Update heights
    updateHeight(y);
    updateHeight(x);

    // Return new root
    return x;
}
```

- **左旋**:

```cpp
AVLNode *leftRotate(AVLNode *x) {
    AVLNode *y = x->right;
    AVLNode *T2 = y->left;

    // Perform rotation
    y->left = x;
    x->right = T2;

    // Update heights
    updateHeight(x);
    updateHeight(y);

    // Return new root
    return y;
}
```

##### 插入操作

插入是AVL树中最关键的操作之一，因为它需要在插入新节点后检查树是否失衡，并进行相应的旋转操作来恢复平衡。

```cpp
AVLNode* insert(AVLNode* node, int key) {
    // 1. Perform the normal BST insertion
    if (node == nullptr)
        return(new AVLNode(key));

    if (key < node->key)
        node->left = insert(node->left, key);
    else if (key > node->key)
        node->right = insert(node->right, key);
    else // Equal keys are not allowed in BST
        return node;

    // 2. Update height of this ancestor node
    updateHeight(node);

    // 3. Get the balance factor of this ancestor node to check whether
    // this node became unbalanced
    int balance = getBalance(node);

    // If this node becomes unbalanced, then there are 4 cases

    // Left Left Case
    if (balance > 1 && key < node->left->key)
        return rightRotate(node);

    // Right Right Case
    if (balance < -1 && key > node->right->key)
        return leftRotate(node);

    // Left Right Case
    if (balance > 1 && key > node->left->key) {
        node->left = leftRotate(node->left);
        return rightRotate(node);
    }

    // Right Left Case
    if (balance < -1 && key < node->right->key) {
        node->right = rightRotate(node->right);
        return leftRotate(node);
    }

    /* return the (unchanged) node pointer */
    return node;
}
```

### 红黑树

红黑树是一种自平衡的二叉查找树，是一种高效的查找树。它可在 $O(logN)$ 时间内完成查找、增加、删除等操作。

- 节点是红色或黑色。
- 根是黑色。
- 所有叶子都是黑色（叶子是NIL节点）。
- 每个红色节点必须有两个黑色的子节点。（从每个叶子到根的所有路径上不能有两个连续的红色节点。）
- 从任一节点到其每个叶子的所有简单路径都包含相同数目的黑色节点（简称黑高）。



## 图

### 图的存储结构

##### 1.邻接矩阵

利用一维数组来存储节点信息，用二维数组来存储图的信息

无向图：二维数组会是一个对称矩阵

想知道某一个顶点的度，就是这个顶点$V_i$代表的是第$i$列的元素之和

有向图：$V_1到V_2$有弧，得到$arc[1][0]=1$

有向图讲究入度和出度，列元素之和为入度，行元素之和为出度



每条边上有权重的图叫网，则邻接矩阵的定义
$$
arc[i][j]=\left\{
                \begin{array}{ll}
                  W_{ij}，若(v_i,v_j)\in E或<v_i,v_j>\in E\\
                  0，若i=j\\
                  \infin，其他
                \end{array}
              \right.
$$


因为权重可能为0，所以其他情况时不要用0



##### 2.邻接表

数组与链表结合的存储方法

表节点为数组，后面链上边表节点，无向图中后面会链上所有有边节点，有向图中只链进入的节点

带权重的可以在边表节点中加weight数据域

不管是邻接表还是逆邻接表，有向图中对于出度和入读的计算总有一个需要遍历整个数组



##### 3.十字链表

顶点表:

| data | firstin | firstout |
| ---- | ------- | -------- |

边表节点：

| tailvex | headvex | headlink | taillink |
| ------- | ------- | -------- | -------- |

tailvex:指的是弧起点

firstin指向headvex

##### 4.邻接多重表

##### 5.边集数组



### 图的遍历

##### 深度优先算法（DFS）

简单来说就是一个递归的过程，单独存储一个visit数组作为以访问过的节点，

以邻接矩阵存储时，查找每个顶点的邻接点需要$O(n^2)$的时间，而邻接表做存储结构时，取决于顶点和边的数量，需要$O(n+e)$的时间，



##### 广度优先算法（BFS）

队列！！！

搜寻完一个节点后把他的下一层节点加入队列



BFS和DFS在时间复杂度上没有太多区别，选取怎样的方法取决于你要干啥



##### 最小生成树

###### 普利姆（Prim）算法

```c
void MiniSpanTree(Graph G) {
	int min, i, j, k
	int index[MAXVEX];					//存储下标，当前低价格下的起始节点
	int lowcost[MAXVEX];				//到此节点的最低消费
	index[0] = 0;
	lowcost[0] = 0;
	for (i = 1; i < G.num; i++) {			//初始化，把0到每个节点的权数载入
		lowcost[i] = G.arc[0][i];
		index[i] = 0;
	}
	for (i = 0; i < G.num; i++) {			//最小生成树的生成过程
		min = INFINTY;
		j = 1;
		k = 0;
		while (j < G.num) {				//寻找当前最小权数
			if (lowcost[j] != 0 && lowcost[j] < min) {
				min = lowcost[j];
				k = j;					//获得准备去的下标
			}
			j++
		}

		lowcost[k] = 0;					//lowcost=0说明此节点已载入
		for (j = 1; j < G.num; j++) {		//刷新新的最短距离
			if (lowcost[j] != 0 && lowcost[j] > G.arc[k][j]) {
				lowcost[j] = G.arc[k][j];	//如果此节点没有为0，且有更短到此节点的距离
				index[j] = k;}}}
	}
```



###### 克鲁斯卡尔（Kruskal）算法

利用边集数组，从小到大的权重编号依次排列，难点在于如何排除重复的节点



并查集：主要作用是判断某一个节点是否属于某棵树，其方法就是不断的合并树，让一个树的根节点成为另一颗树的子树，在此算法中的parent数组和Find函数就是此数据结构的应用

```c
int main MiniSpanTree_Kruskal(MGraph G)
{
	int n,m,i;
	Edge edge[MAXEDGE];
	int parent[MAXNODE];
	//省略把Edge顺次排序的代码
	
	for(i=0;i<MAXNODE;i++)
		parent[i]=0;			//初始化所有树的根
	for(i=0;i<MAXEDGE;i++)
	{
	    m=Find(edge,edge[i]->begin);
		n=Find(edge,edge[i]->end);
		if(m!=n)
		{
			parent[n]=m;		//合并树
		}
		printf("(%d,%d) %d\n",edge[i].begin,edge[i].end,edge[i].weight);
	}
}
int Find(int *parent,int i){
	while(parent[i]!=0)
	{
		i=parent[i];			//寻找根节点
	}
	return i;
}
```

### 并查集

1. 查找根节点
2. 不同则合并
3. 矮的树放在低位

可以证明这样构造并查集，树的深度不会超过$$log_2N$$

4. 顺便压缩路径

这样树的深度不会超过 $$lgN$$



# 算法分析与设计

## 序言

时间复杂度：用算法的**基本操作（算法中最重要的操作）**的执行次数来度量算法的时间效率
$$
T(n) ≈ copC(n)
$$
**一个需要指数级操作次数的算法只能用来解决规模非常小的问题**



### 渐进符号

**f(n)<=Cg(n)**，记作t(n)=O(g(n))

f(n)≥Cg(n)，记作f(n)= **Ω**(g(n))

使用极限的方法来求





### NPC问题

#### P问题

如果一个问题可以找到一个多项式级复杂度的解法，那么该问题就是P问题。

#### NP问题

指那些可以在多项式时间内被验证的问题。换句话说，如果一个解被提供给你，你可以在多项式时间内验证它是否是正确的。

#### P与NP

- 所有的P问题都是NP问题。
- NP问题一定是P问题吗？
  - 这个问题无解



#### 归约

“问题A可约化为问题B”的一个隐含的含义： B的时间复杂度 >= A的时间复杂度 



#### NPC问题（NP完全）

NPC问题是一类特殊的NP问题。一个问题被称为NP完全，如果它既属于NP问题集合，又具有一个特殊的性质：任何一个NP问题都可以在多项式时间内约归到该问题。

NPC问题属于NP问题，但是NP问题不一定属于NPC问题

证明：

首先，证明它是一个NP问题；

然后，证明一个已知的NPC问题可以归约为它。（根据归约的传递性）



#### NP难问题

某个NPC问题可以归约为一个特定的问题，但这个问题并不是一个NP问题，则称这个问题为NP-Hard问题。

NP难问题（NP-Hard）和NP完全问题（NPC，NP-Complete）是两个相关但不完全相同的概念。

<img src="https://pic2.zhimg.com/80/v2-1a4f4cfd668c28c1b47c266c7fe85199_720w.webp" alt="img" style="zoom: 150%;" />



简答题：简述三个渐进复杂的公式的含义

简述NP，NP难，NP-完成等术语，如何证明题目是NP-难算法

如何证明一个问题是NP难问题：

1. 挑选一个已知具有NP难的问题
2. 证明如果从L1的任意实例I（在多项式时间内确定）获得L2的一个实例I'，由I'的解能确定L1实例的I的解
3. 有传递性可以得出L2是NP-难的

## 递归

思想和栈比较相同，我们需要找到循环终止的条件

步骤：

1. 明白函数想干嘛
2. 寻找函数终止条件
3. 找出函数的等价关系时



时间复杂度分析：

- 决定用哪个参数作为输入规模的度量
- 找出算法的基本操作
- 检查对相同规模的输入，基本操作的执行次数是否相同，如果不同，必须对最差、平均及最优效率单独研究
- 建立一个递推关系式及相应的初始条件
- 求解这个递归关系式，或者至少确定解的增长次数

**递归的简洁性可能会掩饰其算法的效率复杂性**



## 分治

**分治法的几个步骤：**

1、将原始问题划分为k个相同类型的子问题。（问题：为什么？）

2、子问题不可解还可继续划分。（问题：分到什么时候结束？）

3、求解每个子问题。

4、将每个最小子问题的解合并成原问题的解。



**分治法适用条件：**

1、原始可分解，且分解出来的子问题和原始问题就有相同的类型。

2、分解出来的子问题到很小时可以很容易（在很短的时间和空间内能求解）求解。

3、**子问题的解能合并。**（这是能否使用分治算法的关键）



**最优子结构指的是**问题的最优解包含了子问题的最优解



### 归并排序

归并排序的时间复杂度任何情况下都是 O(nlogn)

空间复杂度是是指在某个时刻最大的空间数量，为n个



### 分治矩阵乘法(nop)

c++步骤：

1. 声明类
2. 主要递归函数：如果矩阵的长度大于2，则继续分割
3. 辅助函数：矩阵分割，矩阵合并，矩阵相加，2阶矩阵相乘



### 棋盘覆盖问题(nop)

函数变量：tr tc左上角点，dr dc当前分治中特殊点，size长度

如果宽度等于2，就覆盖除了特殊点的其他点

如果宽度不等于2，就对区域四分
$$
T(n)=O(4^k)
$$


### *寻找第k小数

时间复杂度：O(n)

```pseudocode
function FindKthSmallest(arr, left, right, k):
    // 基本情况：当数组中只有少量元素时，直接返回第k小的数
    if right - left + 1 <= 5:
       	sort(arr[left:right+1])
       	return arr[left+k-1]

    // 将数组划分为大小为5的子数组
    numGroups = (right - left + 1) / 5
    medians = int[numGroups]

    for i from 0 to numGroups - 1:
        groupLeft = left + i * 5
        groupRight = groupLeft + 4

        if groupRight > right:
            groupRight = right

        medians[i] = FindKthSmallest(arr, groupLeft, groupRight, 3)

    // 找到中位数的中位数（中位数数组的中位数）
    medianOfMedians = FindKthSmallest(medians, 0, numGroups - 1, numGroups / 2 + 1)

    // 使用中位数的中位数作为pivot，划分数组
    pivotIndex = Partition(arr, left, right, medianOfMedians)

    // 计算pivot的位置与k的关系
    pivotRank = pivotIndex - left + 1

    if k == pivotRank:
        return arr[pivotIndex]
    else if k < pivotRank:
        return FindKthSmallest(arr, left, pivotIndex - 1, k)
    else:
        return FindKthSmallest(arr, pivotIndex + 1, right, k - pivotRank)

function Partition(arr, left, right, pivot):
    //找到pivot在数组中的位置，并将其移动到最右边
    pivotIndex = left

    for i from left to right - 1:
        if arr[i] == pivot:
            swap(arr[i],arr[right])
            break

    pivot = arr[right]
    i = left

    for j from right - 1 to i:
        if arr[j] <= pivot:
            i = i + 1
            swap(arr[i],arr[j])

   	swap(arr[i + 1],arr[right])
   	return i + 1

```





### 求二维图中最近的两个点

按x升序排列

1. 对半分进行递归调用
2. 当分到只剩两个时，直接返回距离
3. 合并问题，从左边，右边和中间判断最小



### 快速傅里叶变化（FFT）

$$
P(x):[p_0,p_1,...,p_{n-1}] \\
w=e^{\frac{2\pi i}{n}}:[w^0,w^1,...,w^{n-1}]
$$

将w带入p(x)求解

可以对整个FFT公式左右分治

左侧：
$$
P_e(x):[p_0,p_2,...,p_{n-2}] \\
w=e^{\frac{2\pi i}{n}}:[w^0,w^1,...,w^{n-1}]
$$

右侧：
$$
P_o(x):[p_1,p_3,...,p_{n-1}] \\
w=e^{\frac{2\pi i}{n}}:[w^0,w^1,...,w^{n-1}]
$$

![微信图片_20230427084257](assets/微信图片_20230427084257.jpg)



## 减治法

分治法是把一个大问题划分为若干个子问题，分别求解各个子问题，然后再把子问题的解进行合并得到原问题的解。

减治法同样是把一个大问题划分为若干个子问题，但是这些子问题不需要分别求解，只需求解其中的一个子问题，因而也无需对子问题的解进行合并。

所以，严格的说，减治法应该是一种退化了的分治法，时间复杂性一般是$$O(log_2 n)$$。

（1）原问题的解只存在于其中一个较小规模的子问题中；

（2）原问题的解与其中一个较小规模的解之间存在某种对应关系

<img src="assets/image-20230620202057325.png" alt="image-20230620202057325" style="zoom:80%;" />



## 动态规划

动态规划的基本思想是将一个大问题分解为若干个重叠子问题，并通过求解子问题的最优解来得到原问题的最优解。

动态规划的核心思想是"最优子结构"和"重叠子问题"。

1. 最优子结构：指原问题的最优解包含了子问题的最优解。换句话说，通过求解子问题的最优解可以推导出原问题的最优解。
2. 重叠子问题：指在求解原问题时，会重复地遇到相同的子问题。为了避免重复计算，动态规划使用一种记忆化的技术，将已经求解过的子问题的结果保存起来，以便需要时直接查找而不需要重新计算。

动态规划通常使用一个表格或数组来存储子问题的解，这被称为"动态规划表"或"记忆化数组"。通过填充表格中的元素，可以逐步求解更大规模的子问题，直到最终解决原问题。



优点：

1. 最优化问题求解：动态规划适用于求解最优化问题，可以找到问题的最优解。通过将问题拆分为子问题并利用最优子结构，可以有效地求解复杂的最优化问题。
2. 减少重复计算：动态规划使用记忆化技术，通过保存已经求解过的子问题的结果，避免重复计算。这样可以大幅度减少计算量，提高算法的效率。
3. 时间复杂度优化：相对于朴素的递归方法，动态规划通常可以将指数级的时间复杂度优化为多项式级别的复杂度，大大提高了算法的效率。

缺点：

1. 占用空间大
2. 不适用于所有算法



### 求二项式系数

利用二维数组存储n从1开始的对角线数组，$$dp[i][k]=dp[i-1][k]+dp[j-1][k-1]$$



### 拓扑图中最长距离

依次遍历入度为0的点，判断当前节点大小：
$$
dis[i]=max\{dis[i],dis[j]+dis(i,j)\}
$$

```pseudocode
function DAG(G(V,E)){
	topologically sort the node in G
    
    path[0]=0
    path[sort[1]]=0
    for i = 1 to sort.size:
    {
        max_path=0
        for j = 1 to i:
        {
            if edge[sort(j)][sort(i)]:
                if path[sort[j]]+edge[sort[j]][sort[i]]>max_path: 
                    max_path=path[sort[j]]+edge[sort[j]][sort[i]];
        }
        path[sort[i]]=max_path;
    }

    max = max(path)
    return max
}
```



### 加空格编辑距离

编辑距离：将一个字符串变成另一个字符串的最小改变数量

对应有两种情况：
$$
x[i]==y[j]时，&E[i][j]=E[i-1][j-1]\\
x[i]!=y[j]时，&E[i][j]=min(E[i-1][j],E[i][j-1],E[i-1][j-1])+1
$$



### 背包问题

#### 01背包

定义变量`bp[i][j]: 将前i件物品装进限重为j的背包可以获得的最大价值`

```pseudocode
function 01package(w[1...n],v[1...n]){
	for i=1 to n do
		for j=1 to n do
			dp[i][j] = max(dp[i-1][j],dp[i-1][j-w[i]]+v[i];
	return dp[n][n];
}
```



#### 完全背包

与01背包问题只有一个不同地方：

状态量的定义应该改为：`dp[i][j] = max(dp[i-1][j],dp[i][j-w[i]]+v[i];`

这样就是说可以在选择每个物体的时候，还可以选择要装入几个物体



#### 多重背包

状态方程：

```c
# k为装入第i种物品的件数, k <= min(n[i], j/w[i])
dp[i][j] = max{(dp[i-1][j − k*w[i]] + k*v[i]) for every k}
```





### 链式矩阵相乘

求解矩阵链相乘问题时动态规划算法的另一个例子。给定一个n个矩阵的序列（矩阵链）<A1,A2,...,An>，我们希望计算它们的乘积  A1A2...An

例如如果有矩阵链为<A1,A2,A3,A4>,则共有5种完全括号化的矩阵乘积链。

(A1(A2(A3A4)))、(A1((A2A3)A4))、((A1A2)(A3A4))、((A1(A2A3))A4)、((A1(A2A3))A4) 对矩阵链加括号的方式会对乘积运算的代价产生巨大影响。

 因此，A(i)A(i+1)...A(j)的最小代价括号化方案的递归求解公式变为：
    ①如果i=j，m[i,j]=0
    ②如果i<j，m[i,j]=min{m[i,k]+m[k+1,j]+p(i-1)p(k)p(j)}  i<=k<j

```pseudocode
function MATRIX_CHAIN_ORDER(P(0...n),i,j):
	if i==j then:
		m[i][j] := 0;
	if i<j then:
		for x := i to j
			left := MATRIX_CHAIN_ORDER(P(0...n),i,x)
			right := MATRIX_CHAIN_ORDER(P(0...n),x+1,j)
			m[i][j] = min(left+right+P(i-1)P(k)P(j),m[i][j]);
	return m[i][j];
```



### 全源最短路径问题

```pseudocode
For i=1 to n do:
	for j=1 to n do
		dij(0)= ∞;
For all (i,j) ∈E do 
		dij(0)=w(i, j);
For k=1 to n do: 
		for i=1 to n do:
      		for j=1 to n do
      			dij(k) = min{dij(k-1) , dik(k-1) + dkj(k-1)}
return D(n);
```



## DFS BFS

### DFS

#### 递归

```pseudocode
function dfs(n){
	if n==node: 
		return n;
	for nb in n.邻居:
		if !nb.ischecked:
			nb.ischecked = True
			return dfs(nb);
}
```



#### 非递归

```pseudocode
function dfs(n){
	var s:stack
	s.push(n)
	while not s.empty:
		node = s.pop()
		for nb in n.邻居:
			if !nb.ischecked:
				if nb = node:
					return nb;
				nb.ischecked = True
				dfs(nb);
}
```



### 求连通分量

使用BFS或者DFS对每个未判断的点判断一次，一次BFS或者DFS可以遍历完一个连通分量



## 贪心

贪心算法是一种优化算法，它的基本思想是在每一步选择中都采取当前状态下最优的选择，以期望最终达到全局最优解。

贪心算法的关键在于贪心选择策略，即每一步选择时都选择当前看起来最优的解决方案。这里的最优是指局部最优，也就是在当前步骤下能够获得最大（或最小）收益的选择。通过连续地进行这样的局部最优选择，最终希望能够达到全局最优解。

需要注意的是，贪心算法并不是适用于所有问题的解决方法。它只适用于一些具有贪心选择性质的问题，即通过局部最优选择就能够得到全局最优解的问题。对于一些问题，贪心算法可能会得到次优解或者根本无法得到正确解答。



### Prim算法

思想：使用贪心算法解决最小生成树问题，它的基本思想是通过逐步添加未访问顶点相连的最小权重边来构建一个连通图，使得图的总权重最小，并最终形成一个包含所有顶点的树。

时间复杂度：O(vloge)



### Kruska算法

思想：Kruskal算法的贪心选择性质在于每次选择权重最小的边，并且通过判断是否会形成环路来保证了每一步都选择了当前最优的解决方案。通过不断添加边并合并连通分量，最 终形成了一个最小生成树。

时间复杂度：O(E log E)



### dijkstra算法

任务：求单源最短路径，每次选择到原点最短的点，加入到已选择的边集合中，使用选择的点来刷新与他连接的点

不能处理有负权边的图，因为这个方法不会重新更新已选择的点



### Bellman-Ford算法

可以判断是否存在负值

```pseudocode
function BellmanFord(Graph, source):
    // 初始化距离数组和前驱数组
    distance[source] = 0
    predecessor[source] = null

    // 对所有顶点进行V-1次迭代
    for i from 1 to |V| - 1:
        // 对每条边进行松弛操作
        for each edge (u, v, w) in Graph:
            if distance[u] + w < distance[v]:
                distance[v] = distance[u] + w
                predecessor[v] = u

    // 检测是否存在负权环
    for each edge (u, v, w) in Graph:
        if distance[u] + w < distance[v]:
            return "存在负权环"

    return distance[], predecessor[]
```



### SPFA

选择性松弛，是Bellman-Ford的优化算法，我们会发现每一次松弛操作都对所有边做了一次操作，但是我们每次更新都未必会真的更新最短距离，SPFA就是对这个优化，如果距离缩小了，就将其放入队列中去，每次从队列中取第一个数，更新与他相连的点



### Floyd算法

求一个图中 **所有点到所有点** 最短路径的算法，时间复杂度 O(n3)



### 贪心正确性的证明

第一步：符合贪心选择的特性（Greedy Choice Property）

我们需要证明我们的第一个选择（贪心选择 Greedy Choice，First Choice）包含在某些最优解中

第二步：符合归纳法结构（Inductive Structure）

我们需要证明第一个选择（贪心选择）cˆ之后，子问题P′和原问题P还是同一类问题，意味着我们的选择不改变问题的结构，并且子问题P′的解可以和第一个选择（贪心选择）cˆ合并

第三步：最优子结构（Optimal Substructure）

如果我们可以最优的解决子问题P′，我们可以将子问题P′的解和贪心选择cˆ得到原问题P的解



## 排序

判断k次比较能否对n个数，进行排序：

比较$$2^k与n的大小关系$$

![img](https://www.runoob.com/wp-content/uploads/2019/03/0B319B38-B70E-4118-B897-74EFA7E368F9.png)

### 快速排序

```cpp
void quick_sort(int q[], int l, int r)
{
    if (l >= r) return;

    int i = l - 1, j = r + 1, x = q[l + r >> 1];
    while (i < j)
    {
        do i ++ ; while (q[i] < x);
        do j -- ; while (q[j] > x);
        if (i < j) swap(q[i], q[j]);
    }
    quick_sort(q, l, j), quick_sort(q, j + 1, r);
}
```

最快：$O(n\log n)$

平均：$O(n\log n)$

最慢：$O(n^2)$，每次选取的都是最小或者最大的数字

### 归并排序

```cpp
void merge_sort(int q[], int l, int r)
{
    if (l >= r) return;

    int mid = l + r >> 1;
    merge_sort(q, l, mid);
    merge_sort(q, mid + 1, r);

    int k = 0, i = l, j = mid + 1;
    while (i <= mid && j <= r)
        if (q[i] <= q[j]) tmp[k ++ ] = q[i ++ ];
        else tmp[k ++ ] = q[j ++ ];

    while (i <= mid) tmp[k ++ ] = q[i ++ ];
    while (j <= r) tmp[k ++ ] = q[j ++ ];

    for (i = l, j = 0; i <= r; i ++, j ++ ) q[i] = tmp[j];
}
```

最好情况时间复杂度：$O(n\log n)$

平均情况时间复杂度：$O(n\log n)$

最坏情况时间复杂度：$O(n\log n)$

注意：归并排序空间复杂度为$n$

### 计数排序



### 堆排序

① 将待排序的序列构造成一个最大堆，此时序列的最大值为根节点

② 依次将根节点与待排序序列的最后一个元素交换

③ 再维护从根节点到该元素的前一个节点为最大堆，如此往复，最终得到一个递增序列

构建堆时间复杂度：$$O(n)$$

堆调整的时间复杂度为$$O(log n)$$

```pseudocode
// 堆排序函数
function heapSort(arr):
    n = arr.length

    // 构建最大堆
    for i from n/2 - 1 down to 0:
        heapify(arr, n, i)

    // 依次取出堆顶元素，进行排序
    for i from n-1 down to 1:
        swap(arr[0], arr[i]) // 将当前最大元素（堆顶）与最后一个元素交换
        heapify(arr, i, 0) // 对剩余的元素重新构建最大堆

// 堆调整函数（递归实现）
function heapify(arr, n, i):
    largest = i // 初始化最大元素为当前节点
    left = 2 * i + 1
    right = 2 * i + 2

    // 比较左子节点和根节点
    if left < n and arr[left] > arr[largest]:
        largest = left

    // 比较右子节点和当前最大节点
    if right < n and arr[right] > arr[largest]:
        largest = right

    // 如果最大节点不是当前节点，则交换节点并递归调整堆
    if largest != i:
        swap(arr[i], arr[largest])
        heapify(arr, n, largest)

// 交换函数
function swap(a, b):
    temp = a
    a = b
    b = temp
```



## 回溯法(BackTracking)

​		回溯法是从初始状态出发，按照深度优先搜索的方式，根据产生子结点的条件约束，搜索问题的解。当发现当前结点不满足求解条件时，就回溯，尝试其他的路径。回溯法是一种“能进则进，进不了则换，换不了则退”的搜索方法。



### 八皇后

```pseudocode
function backtrack(k){
	if k==max:
		print(ans);
	else:
		for i:=1 to max:
			for j:=1 to k:
				if ans[j] == i || abs(k-j)==abs(ans[j]-i):
					flag:=False
					break;
			if flag != False:
				ans[k]:=i
				backtrack(k+1);
}
```



## 分支限界法

求解目标是找出符合约束函数的一个解，或者是找出最优解。通常采用广度优先算法

### 01背包问题

优先队列法：

根据上界函数：$$ub=v+(W-w)(v_i+1/w_i+1)$$

步骤：

1. 基于可行结点相应的`子树最大价值上界优先级`，从堆中选择一个节点（根节点）作为当前可扩展结点。
2. 检查当前扩展结点的左儿子结点的可行性。
3. 如果左儿子结点是可行结点，则将它加入到子集树和活结点优先队列中。
4. 当前扩展结点的右儿子结点一定是可行结点，`仅当右儿子结点满足上界函数约束时,才将它加入子集树和活结点优先队列。`
5. 当扩展到叶节点时，算法结束，叶子节点如果其价值是最大的，对应的解即为问题的最优值。

<img src="assets/image-20230620162650694.png" alt="image-20230620162650694" style="zoom: 67%;" />
